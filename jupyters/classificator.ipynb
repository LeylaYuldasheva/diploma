{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Layla\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Layla\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Layla\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Layla\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Layla\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Layla\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Layla\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Layla\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Layla\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Layla\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Layla\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Layla\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['Dan_Radcliffe.csv', 'Emma_Watson.csv', 'Rupert_Grint.csv', 'Harrison_Ford.csv', 'Will_Smith.csv', 'Halle_Berry.csv']\n",
    "dfs = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, index_col = 0)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>class</th>\n",
       "      <th>descriptor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan_Radcliffe\\10.PNG</td>\n",
       "      <td>Dan_Radcliffe</td>\n",
       "      <td>-0.01745985820889473 0.10399903357028961 0.059...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dan_Radcliffe\\100.PNG</td>\n",
       "      <td>Dan_Radcliffe</td>\n",
       "      <td>-0.10777680575847626 0.07684307545423508 0.040...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dan_Radcliffe\\101.PNG</td>\n",
       "      <td>Dan_Radcliffe</td>\n",
       "      <td>-0.10304909199476242 0.08664718270301819 0.038...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dan_Radcliffe\\102.PNG</td>\n",
       "      <td>Dan_Radcliffe</td>\n",
       "      <td>-0.06392291933298111 0.09306670725345612 0.059...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dan_Radcliffe\\104.PNG</td>\n",
       "      <td>Dan_Radcliffe</td>\n",
       "      <td>-0.10605598986148834 0.07336850464344025 -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Halle_Berry\\995.jpg</td>\n",
       "      <td>Halle_Berry</td>\n",
       "      <td>-0.1652878373861313 0.13762687146663666 0.0526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Halle_Berry\\996.jpg</td>\n",
       "      <td>Halle_Berry</td>\n",
       "      <td>-0.12461502104997635 0.10574141144752502 0.033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Halle_Berry\\997.jpg</td>\n",
       "      <td>Halle_Berry</td>\n",
       "      <td>-0.12324288487434387 0.11619621515274048 0.040...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Halle_Berry\\998.jpg</td>\n",
       "      <td>Halle_Berry</td>\n",
       "      <td>-0.1603611260652542 0.08367139101028442 0.0606...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Halle_Berry\\999.jpg</td>\n",
       "      <td>Halle_Berry</td>\n",
       "      <td>-0.1449565440416336 0.12895521521568298 0.0235...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3306 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  img_path          class  \\\n",
       "0     Dan_Radcliffe\\10.PNG  Dan_Radcliffe   \n",
       "1    Dan_Radcliffe\\100.PNG  Dan_Radcliffe   \n",
       "2    Dan_Radcliffe\\101.PNG  Dan_Radcliffe   \n",
       "3    Dan_Radcliffe\\102.PNG  Dan_Radcliffe   \n",
       "4    Dan_Radcliffe\\104.PNG  Dan_Radcliffe   \n",
       "..                     ...            ...   \n",
       "585    Halle_Berry\\995.jpg    Halle_Berry   \n",
       "586    Halle_Berry\\996.jpg    Halle_Berry   \n",
       "587    Halle_Berry\\997.jpg    Halle_Berry   \n",
       "588    Halle_Berry\\998.jpg    Halle_Berry   \n",
       "589    Halle_Berry\\999.jpg    Halle_Berry   \n",
       "\n",
       "                                            descriptor  \n",
       "0    -0.01745985820889473 0.10399903357028961 0.059...  \n",
       "1    -0.10777680575847626 0.07684307545423508 0.040...  \n",
       "2    -0.10304909199476242 0.08664718270301819 0.038...  \n",
       "3    -0.06392291933298111 0.09306670725345612 0.059...  \n",
       "4    -0.10605598986148834 0.07336850464344025 -0.03...  \n",
       "..                                                 ...  \n",
       "585  -0.1652878373861313 0.13762687146663666 0.0526...  \n",
       "586  -0.12461502104997635 0.10574141144752502 0.033...  \n",
       "587  -0.12324288487434387 0.11619621515274048 0.040...  \n",
       "588  -0.1603611260652542 0.08367139101028442 0.0606...  \n",
       "589  -0.1449565440416336 0.12895521521568298 0.0235...  \n",
       "\n",
       "[3306 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(dfs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_names = {\n",
    "    0 : 'Harrison_Ford',\n",
    "    1 : 'Dan_Radcliffe',\n",
    "    2 : 'Emma_Watson',\n",
    "    3 : 'Rupert_Grint',\n",
    "    4 : 'Will_Smith',\n",
    "    5 : 'Halle_Berry',\n",
    "}\n",
    "names_to_label = {\n",
    "   'Harrison_Ford' : 0 ,\n",
    "    'Dan_Radcliffe': 1,\n",
    "    'Emma_Watson': 2,\n",
    "    'Rupert_Grint': 3,\n",
    "    'Will_Smith' :4,\n",
    "    'Halle_Berry' : 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>class</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan_Radcliffe\\10.PNG</td>\n",
       "      <td>Dan_Radcliffe</td>\n",
       "      <td>-0.01745985820889473 0.10399903357028961 0.059...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dan_Radcliffe\\100.PNG</td>\n",
       "      <td>Dan_Radcliffe</td>\n",
       "      <td>-0.10777680575847626 0.07684307545423508 0.040...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dan_Radcliffe\\101.PNG</td>\n",
       "      <td>Dan_Radcliffe</td>\n",
       "      <td>-0.10304909199476242 0.08664718270301819 0.038...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dan_Radcliffe\\102.PNG</td>\n",
       "      <td>Dan_Radcliffe</td>\n",
       "      <td>-0.06392291933298111 0.09306670725345612 0.059...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dan_Radcliffe\\104.PNG</td>\n",
       "      <td>Dan_Radcliffe</td>\n",
       "      <td>-0.10605598986148834 0.07336850464344025 -0.03...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Halle_Berry\\995.jpg</td>\n",
       "      <td>Halle_Berry</td>\n",
       "      <td>-0.1652878373861313 0.13762687146663666 0.0526...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Halle_Berry\\996.jpg</td>\n",
       "      <td>Halle_Berry</td>\n",
       "      <td>-0.12461502104997635 0.10574141144752502 0.033...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Halle_Berry\\997.jpg</td>\n",
       "      <td>Halle_Berry</td>\n",
       "      <td>-0.12324288487434387 0.11619621515274048 0.040...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Halle_Berry\\998.jpg</td>\n",
       "      <td>Halle_Berry</td>\n",
       "      <td>-0.1603611260652542 0.08367139101028442 0.0606...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Halle_Berry\\999.jpg</td>\n",
       "      <td>Halle_Berry</td>\n",
       "      <td>-0.1449565440416336 0.12895521521568298 0.0235...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3306 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  img_path          class  \\\n",
       "0     Dan_Radcliffe\\10.PNG  Dan_Radcliffe   \n",
       "1    Dan_Radcliffe\\100.PNG  Dan_Radcliffe   \n",
       "2    Dan_Radcliffe\\101.PNG  Dan_Radcliffe   \n",
       "3    Dan_Radcliffe\\102.PNG  Dan_Radcliffe   \n",
       "4    Dan_Radcliffe\\104.PNG  Dan_Radcliffe   \n",
       "..                     ...            ...   \n",
       "585    Halle_Berry\\995.jpg    Halle_Berry   \n",
       "586    Halle_Berry\\996.jpg    Halle_Berry   \n",
       "587    Halle_Berry\\997.jpg    Halle_Berry   \n",
       "588    Halle_Berry\\998.jpg    Halle_Berry   \n",
       "589    Halle_Berry\\999.jpg    Halle_Berry   \n",
       "\n",
       "                                            descriptor  labels  \n",
       "0    -0.01745985820889473 0.10399903357028961 0.059...       1  \n",
       "1    -0.10777680575847626 0.07684307545423508 0.040...       1  \n",
       "2    -0.10304909199476242 0.08664718270301819 0.038...       1  \n",
       "3    -0.06392291933298111 0.09306670725345612 0.059...       1  \n",
       "4    -0.10605598986148834 0.07336850464344025 -0.03...       1  \n",
       "..                                                 ...     ...  \n",
       "585  -0.1652878373861313 0.13762687146663666 0.0526...       5  \n",
       "586  -0.12461502104997635 0.10574141144752502 0.033...       5  \n",
       "587  -0.12324288487434387 0.11619621515274048 0.040...       5  \n",
       "588  -0.1603611260652542 0.08367139101028442 0.0606...       5  \n",
       "589  -0.1449565440416336 0.12895521521568298 0.0235...       5  \n",
       "\n",
       "[3306 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'] = df['class'].map(names_to_label)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    desc = row['descriptor']\n",
    "    values = [float(x) for x in desc.split()]\n",
    "    values = np.array(values)\n",
    "    X.append(values)\n",
    "X = np.array(X)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['labels'].values\n",
    "#Y = utils.to_categorical(Y, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X),type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=73, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9924471299093656"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Layla\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.66730807025883"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=73)\n",
    "model = LogisticRegression(random_state=73)\n",
    "result = cross_val_score(model, X, Y, cv=kfold)\n",
    "result.mean()*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = utils.to_categorical(y_test, 6)\n",
    "y_train = utils.to_categorical(y_train, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Layla\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Создаем последовательную модель\n",
    "nn = Sequential()\n",
    "# Входной полносвязный слой\n",
    "nn.add(Dense(64, input_dim=128, activation=\"relu\"))\n",
    "# Выходной полносвязный слой\n",
    "nn.add(Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 8,646\n",
      "Trainable params: 8,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nn.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2644 samples, validate on 662 samples\n",
      "Epoch 1/100\n",
      "2644/2644 [==============================] - 1s 243us/sample - loss: 1.7804 - acc: 0.2568 - val_loss: 1.7362 - val_acc: 0.3927\n",
      "Epoch 2/100\n",
      "2644/2644 [==============================] - 0s 149us/sample - loss: 1.7131 - acc: 0.4281 - val_loss: 1.6800 - val_acc: 0.5408\n",
      "Epoch 3/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 1.6673 - acc: 0.5234 - val_loss: 1.6372 - val_acc: 0.6012\n",
      "Epoch 4/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 1.6272 - acc: 0.5862 - val_loss: 1.5966 - val_acc: 0.6073\n",
      "Epoch 5/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 1.5879 - acc: 0.6017 - val_loss: 1.5554 - val_acc: 0.6148\n",
      "Epoch 6/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 1.5470 - acc: 0.6093 - val_loss: 1.5128 - val_acc: 0.6269\n",
      "Epoch 7/100\n",
      "2644/2644 [==============================] - 0s 145us/sample - loss: 1.5037 - acc: 0.6256 - val_loss: 1.4681 - val_acc: 0.6586\n",
      "Epoch 8/100\n",
      "2644/2644 [==============================] - 0s 150us/sample - loss: 1.4572 - acc: 0.6808 - val_loss: 1.4184 - val_acc: 0.6979\n",
      "Epoch 9/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 1.4070 - acc: 0.7179 - val_loss: 1.3651 - val_acc: 0.7492\n",
      "Epoch 10/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 1.3525 - acc: 0.7538 - val_loss: 1.3085 - val_acc: 0.7825\n",
      "Epoch 11/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 1.2940 - acc: 0.7716 - val_loss: 1.2486 - val_acc: 0.7855\n",
      "Epoch 12/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 1.2336 - acc: 0.7772 - val_loss: 1.1870 - val_acc: 0.7855\n",
      "Epoch 13/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 1.1726 - acc: 0.7784 - val_loss: 1.1252 - val_acc: 0.7870\n",
      "Epoch 14/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 1.1103 - acc: 0.7803 - val_loss: 1.0632 - val_acc: 0.7885\n",
      "Epoch 15/100\n",
      "2644/2644 [==============================] - 0s 157us/sample - loss: 1.0482 - acc: 0.7810 - val_loss: 1.0016 - val_acc: 0.7900\n",
      "Epoch 16/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.9871 - acc: 0.7814 - val_loss: 0.9418 - val_acc: 0.7915\n",
      "Epoch 17/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.9278 - acc: 0.7829 - val_loss: 0.8846 - val_acc: 0.7915\n",
      "Epoch 18/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.8709 - acc: 0.7893 - val_loss: 0.8290 - val_acc: 0.8066\n",
      "Epoch 19/100\n",
      "2644/2644 [==============================] - 0s 145us/sample - loss: 0.8165 - acc: 0.8003 - val_loss: 0.7768 - val_acc: 0.8233\n",
      "Epoch 20/100\n",
      "2644/2644 [==============================] - 0s 158us/sample - loss: 0.7652 - acc: 0.8253 - val_loss: 0.7276 - val_acc: 0.8308\n",
      "Epoch 21/100\n",
      "2644/2644 [==============================] - 0s 158us/sample - loss: 0.7170 - acc: 0.8446 - val_loss: 0.6820 - val_acc: 0.8520\n",
      "Epoch 22/100\n",
      "2644/2644 [==============================] - 0s 157us/sample - loss: 0.6716 - acc: 0.8744 - val_loss: 0.6391 - val_acc: 0.8822\n",
      "Epoch 23/100\n",
      "2644/2644 [==============================] - 0s 149us/sample - loss: 0.6294 - acc: 0.9054 - val_loss: 0.5994 - val_acc: 0.9003\n",
      "Epoch 24/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.5900 - acc: 0.9228 - val_loss: 0.5630 - val_acc: 0.9260\n",
      "Epoch 25/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.5534 - acc: 0.9440 - val_loss: 0.5289 - val_acc: 0.9396\n",
      "Epoch 26/100\n",
      "2644/2644 [==============================] - 0s 157us/sample - loss: 0.5195 - acc: 0.9592 - val_loss: 0.4974 - val_acc: 0.9532\n",
      "Epoch 27/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.4880 - acc: 0.9709 - val_loss: 0.4680 - val_acc: 0.9577\n",
      "Epoch 28/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.4589 - acc: 0.9762 - val_loss: 0.4410 - val_acc: 0.9728\n",
      "Epoch 29/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.4319 - acc: 0.9822 - val_loss: 0.4159 - val_acc: 0.9758\n",
      "Epoch 30/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.4069 - acc: 0.9845 - val_loss: 0.3931 - val_acc: 0.9804\n",
      "Epoch 31/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.3837 - acc: 0.9864 - val_loss: 0.3716 - val_acc: 0.9819\n",
      "Epoch 32/100\n",
      "2644/2644 [==============================] - 0s 157us/sample - loss: 0.3622 - acc: 0.9875 - val_loss: 0.3519 - val_acc: 0.9849\n",
      "Epoch 33/100\n",
      "2644/2644 [==============================] - 0s 157us/sample - loss: 0.3422 - acc: 0.9898 - val_loss: 0.3334 - val_acc: 0.9894\n",
      "Epoch 34/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.3237 - acc: 0.9917 - val_loss: 0.3162 - val_acc: 0.9894\n",
      "Epoch 35/100\n",
      "2644/2644 [==============================] - 0s 150us/sample - loss: 0.3065 - acc: 0.9917 - val_loss: 0.3004 - val_acc: 0.9894\n",
      "Epoch 36/100\n",
      "2644/2644 [==============================] - 0s 157us/sample - loss: 0.2906 - acc: 0.9932 - val_loss: 0.2857 - val_acc: 0.9894\n",
      "Epoch 37/100\n",
      "2644/2644 [==============================] - 0s 158us/sample - loss: 0.2757 - acc: 0.9936 - val_loss: 0.2722 - val_acc: 0.9894\n",
      "Epoch 38/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.2619 - acc: 0.9936 - val_loss: 0.2594 - val_acc: 0.9894\n",
      "Epoch 39/100\n",
      "2644/2644 [==============================] - 0s 157us/sample - loss: 0.2491 - acc: 0.9939 - val_loss: 0.2474 - val_acc: 0.9924\n",
      "Epoch 40/100\n",
      "2644/2644 [==============================] - 0s 150us/sample - loss: 0.2371 - acc: 0.9947 - val_loss: 0.2365 - val_acc: 0.9909\n",
      "Epoch 41/100\n",
      "2644/2644 [==============================] - 0s 158us/sample - loss: 0.2261 - acc: 0.9951 - val_loss: 0.2262 - val_acc: 0.9924\n",
      "Epoch 42/100\n",
      "2644/2644 [==============================] - 0s 157us/sample - loss: 0.2157 - acc: 0.9951 - val_loss: 0.2166 - val_acc: 0.9924\n",
      "Epoch 43/100\n",
      "2644/2644 [==============================] - 0s 157us/sample - loss: 0.2061 - acc: 0.9951 - val_loss: 0.2077 - val_acc: 0.9924\n",
      "Epoch 44/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.1971 - acc: 0.9955 - val_loss: 0.1993 - val_acc: 0.9924\n",
      "Epoch 45/100\n",
      "2644/2644 [==============================] - 0s 157us/sample - loss: 0.1887 - acc: 0.9962 - val_loss: 0.1916 - val_acc: 0.9924\n",
      "Epoch 46/100\n",
      "2644/2644 [==============================] - 0s 157us/sample - loss: 0.1807 - acc: 0.9958 - val_loss: 0.1843 - val_acc: 0.9924\n",
      "Epoch 47/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.1734 - acc: 0.9962 - val_loss: 0.1773 - val_acc: 0.9924\n",
      "Epoch 48/100\n",
      "2644/2644 [==============================] - 0s 157us/sample - loss: 0.1665 - acc: 0.9962 - val_loss: 0.1709 - val_acc: 0.9924\n",
      "Epoch 49/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.1601 - acc: 0.9962 - val_loss: 0.1649 - val_acc: 0.9924\n",
      "Epoch 50/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.1540 - acc: 0.9962 - val_loss: 0.1593 - val_acc: 0.9924\n",
      "Epoch 51/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.1483 - acc: 0.9962 - val_loss: 0.1540 - val_acc: 0.9924\n",
      "Epoch 52/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.1430 - acc: 0.9966 - val_loss: 0.1489 - val_acc: 0.9924\n",
      "Epoch 53/100\n",
      "2644/2644 [==============================] - 0s 154us/sample - loss: 0.1380 - acc: 0.9966 - val_loss: 0.1444 - val_acc: 0.9924\n",
      "Epoch 54/100\n",
      "2644/2644 [==============================] - 0s 150us/sample - loss: 0.1332 - acc: 0.9970 - val_loss: 0.1399 - val_acc: 0.9924\n",
      "Epoch 55/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.1288 - acc: 0.9966 - val_loss: 0.1357 - val_acc: 0.9924\n",
      "Epoch 56/100\n",
      "2644/2644 [==============================] - 0s 160us/sample - loss: 0.1245 - acc: 0.9970 - val_loss: 0.1318 - val_acc: 0.9924\n",
      "Epoch 57/100\n",
      "2644/2644 [==============================] - 0s 153us/sample - loss: 0.1206 - acc: 0.9974 - val_loss: 0.1280 - val_acc: 0.9924\n",
      "Epoch 58/100\n",
      "2644/2644 [==============================] - 0s 155us/sample - loss: 0.1168 - acc: 0.9977 - val_loss: 0.1245 - val_acc: 0.9924\n",
      "Epoch 59/100\n",
      "2644/2644 [==============================] - 0s 146us/sample - loss: 0.1132 - acc: 0.9970 - val_loss: 0.1212 - val_acc: 0.9924\n",
      "Epoch 60/100\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.1105 - acc: 0.997 - 0s 157us/sample - loss: 0.1099 - acc: 0.9974 - val_loss: 0.1179 - val_acc: 0.9924\n",
      "Epoch 61/100\n",
      "2644/2644 [==============================] - 0s 158us/sample - loss: 0.1067 - acc: 0.9974 - val_loss: 0.1149 - val_acc: 0.9924\n",
      "Epoch 62/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.1036 - acc: 0.9977 - val_loss: 0.1120 - val_acc: 0.9924\n",
      "Epoch 63/100\n",
      "2644/2644 [==============================] - 0s 146us/sample - loss: 0.1008 - acc: 0.9974 - val_loss: 0.1093 - val_acc: 0.9924\n",
      "Epoch 64/100\n",
      "2644/2644 [==============================] - 0s 145us/sample - loss: 0.0981 - acc: 0.9977 - val_loss: 0.1067 - val_acc: 0.9924\n",
      "Epoch 65/100\n",
      "2644/2644 [==============================] - 0s 146us/sample - loss: 0.0955 - acc: 0.9977 - val_loss: 0.1042 - val_acc: 0.9924\n",
      "Epoch 66/100\n",
      "2644/2644 [==============================] - 0s 150us/sample - loss: 0.0930 - acc: 0.9977 - val_loss: 0.1019 - val_acc: 0.9924\n",
      "Epoch 67/100\n",
      "2644/2644 [==============================] - 0s 144us/sample - loss: 0.0906 - acc: 0.9977 - val_loss: 0.0996 - val_acc: 0.9924\n",
      "Epoch 68/100\n",
      "2644/2644 [==============================] - 0s 145us/sample - loss: 0.0884 - acc: 0.9977 - val_loss: 0.0975 - val_acc: 0.9924\n",
      "Epoch 69/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.0862 - acc: 0.9977 - val_loss: 0.0955 - val_acc: 0.9924\n",
      "Epoch 70/100\n",
      "2644/2644 [==============================] - 0s 150us/sample - loss: 0.0842 - acc: 0.9977 - val_loss: 0.0935 - val_acc: 0.9924\n",
      "Epoch 71/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.0822 - acc: 0.9977 - val_loss: 0.0917 - val_acc: 0.9924\n",
      "Epoch 72/100\n",
      "2644/2644 [==============================] - 0s 146us/sample - loss: 0.0804 - acc: 0.9977 - val_loss: 0.0899 - val_acc: 0.9924\n",
      "Epoch 73/100\n",
      "2644/2644 [==============================] - 0s 145us/sample - loss: 0.0786 - acc: 0.9977 - val_loss: 0.0882 - val_acc: 0.9924\n",
      "Epoch 74/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.0769 - acc: 0.9977 - val_loss: 0.0866 - val_acc: 0.9924\n",
      "Epoch 75/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.0752 - acc: 0.9977 - val_loss: 0.0850 - val_acc: 0.9924\n",
      "Epoch 76/100\n",
      "2644/2644 [==============================] - 0s 154us/sample - loss: 0.0736 - acc: 0.9977 - val_loss: 0.0835 - val_acc: 0.9924\n",
      "Epoch 77/100\n",
      "2644/2644 [==============================] - 0s 146us/sample - loss: 0.0721 - acc: 0.9977 - val_loss: 0.0820 - val_acc: 0.9924\n",
      "Epoch 78/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.0707 - acc: 0.9977 - val_loss: 0.0806 - val_acc: 0.9924\n",
      "Epoch 79/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.0693 - acc: 0.9977 - val_loss: 0.0793 - val_acc: 0.9924\n",
      "Epoch 80/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.0679 - acc: 0.9977 - val_loss: 0.0779 - val_acc: 0.9924\n",
      "Epoch 81/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.0666 - acc: 0.9977 - val_loss: 0.0768 - val_acc: 0.9924\n",
      "Epoch 82/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.0654 - acc: 0.9977 - val_loss: 0.0755 - val_acc: 0.9924\n",
      "Epoch 83/100\n",
      "2644/2644 [==============================] - 0s 156us/sample - loss: 0.0642 - acc: 0.9977 - val_loss: 0.0744 - val_acc: 0.9924\n",
      "Epoch 84/100\n",
      "2644/2644 [==============================] - 0s 150us/sample - loss: 0.0630 - acc: 0.9977 - val_loss: 0.0733 - val_acc: 0.9924\n",
      "Epoch 85/100\n",
      "2644/2644 [==============================] - 0s 158us/sample - loss: 0.0619 - acc: 0.9977 - val_loss: 0.0722 - val_acc: 0.9924\n",
      "Epoch 86/100\n",
      "2644/2644 [==============================] - 0s 145us/sample - loss: 0.0608 - acc: 0.9977 - val_loss: 0.0712 - val_acc: 0.9924\n",
      "Epoch 87/100\n",
      "2644/2644 [==============================] - 0s 146us/sample - loss: 0.0598 - acc: 0.9977 - val_loss: 0.0701 - val_acc: 0.9924\n",
      "Epoch 88/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.0588 - acc: 0.9977 - val_loss: 0.0692 - val_acc: 0.9924\n",
      "Epoch 89/100\n",
      "2644/2644 [==============================] - 0s 157us/sample - loss: 0.0578 - acc: 0.9977 - val_loss: 0.0682 - val_acc: 0.9924\n",
      "Epoch 90/100\n",
      "2644/2644 [==============================] - 0s 145us/sample - loss: 0.0569 - acc: 0.9977 - val_loss: 0.0673 - val_acc: 0.9924\n",
      "Epoch 91/100\n",
      "2644/2644 [==============================] - 0s 145us/sample - loss: 0.0560 - acc: 0.9977 - val_loss: 0.0665 - val_acc: 0.9924\n",
      "Epoch 92/100\n",
      "2644/2644 [==============================] - 0s 146us/sample - loss: 0.0551 - acc: 0.9977 - val_loss: 0.0656 - val_acc: 0.9924\n",
      "Epoch 93/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.0543 - acc: 0.9981 - val_loss: 0.0649 - val_acc: 0.9924\n",
      "Epoch 94/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.0534 - acc: 0.9981 - val_loss: 0.0641 - val_acc: 0.9924\n",
      "Epoch 95/100\n",
      "2644/2644 [==============================] - 0s 153us/sample - loss: 0.0526 - acc: 0.9981 - val_loss: 0.0633 - val_acc: 0.9924\n",
      "Epoch 96/100\n",
      "2644/2644 [==============================] - 0s 151us/sample - loss: 0.0519 - acc: 0.9981 - val_loss: 0.0625 - val_acc: 0.9924\n",
      "Epoch 97/100\n",
      "2644/2644 [==============================] - 0s 145us/sample - loss: 0.0511 - acc: 0.9981 - val_loss: 0.0618 - val_acc: 0.9924\n",
      "Epoch 98/100\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.0509 - acc: 0.998 - 0s 151us/sample - loss: 0.0504 - acc: 0.9981 - val_loss: 0.0611 - val_acc: 0.9924\n",
      "Epoch 99/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.0497 - acc: 0.9981 - val_loss: 0.0604 - val_acc: 0.9924\n",
      "Epoch 100/100\n",
      "2644/2644 [==============================] - 0s 152us/sample - loss: 0.0490 - acc: 0.9981 - val_loss: 0.0597 - val_acc: 0.9924\n"
     ]
    }
   ],
   "source": [
    "history = nn.fit(x_train, y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=100,\n",
    "                 validation_data = (x_test, y_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.save('my_nnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
